---
title: "OHIBC: data_prep_lsp.Rmd"
output: 
  html_document:
    toc: true
  pdf_document:
    toc: true
---
``` {r setup, echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}
library(sp)        # the classes and methods that make up spatial ops in R
# library(gdalUtils) # for gdal_rasterize() function
library(maptools)  # tools for reading and manipulating spatial objects
library(rgeos)
library(rgdal)
library(raster)
library(cleangeo) ### devtools::install_github('eblondel/cleangeo') 


dir_bc  <- '~/github/ohibc'         ### set wd to work in Github OHIBC location
source(file.path(dir_bc, 'R/common.R'))  ### an OHIBC specific version of common.R
source(file.path(dir_bc, 'lsp/R/lsp_fxns.R'))

dir_anx <- file.path(dir_neptune_data, 'git-annex/bcprep') ### git-annex: goal-specific large files
dir_rgn <- file.path(dir_bc, 'regions')       ### github: general buffer region shapefiles
dir_rst <- file.path(dir_anx, 'lsp/spatial')  ### git-annex: goal-specific raster files

### set up the default BC projection to be BC Albers
p4s_bcalb <- '+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'
```
*Compiled on `r date()`*


### Read in BC WDPA-MPA shapefile

NOTE: If BC WDPA file does not yet exist, `get_wdpa_poly()` creates it from the original WDPA-MPA file.  This takes a long time, due to reading in the full WDPA-MPA geodatabase into a SpatialPolygonsDataFrame.

Need to load the WDPA poly into memory for two reasons:

* We need the polygon to help establish the extents for all the rasters to follow.
* Since we need to assign the oldest `STATUS_YR` value to the cell value in the WDPA-MPA raster, we can't use `gdal_rasterize()`; instead we need `raster::rasterize()` which works from memory.

``` {r set up BC WDPA polygons, echo = TRUE, eval = TRUE, warning = FALSE}
poly_wdpa_bc <- lsp_get_wdpa_poly()  ### defaults to BC Albers
```

Check for invalid geometries, and fix them if required.

``` {r check invalid, echo = FALSE, eval = TRUE, verbose = FALSE}

### Check for invalid regions
report <- clgeo_CollectionReport(poly_wdpa_bc)
report$rgn_name <- poly_wdpa_bc$NAME
report <- report %>% filter(valid == FALSE)

if(nrow(report) > 0) {
  cat('Invalid geometries identified:\n')
  print(report %>% dplyr::select(rgn_name, warning_msg))
  
  ### Clean up invalid regions
  poly_wdpa_bc_clean <- clgeo_Clean(poly_wdpa_bc, print.log = FALSE)
  report_clean <- clgeo_CollectionReport(poly_wdpa_bc_clean)
  report_clean$rgn_name <- poly_wdpa_bc$NAME
  report_clean <- report_clean %>%
    filter(valid == FALSE)
  if(nrow(report_clean) == 0) {
    cat('All invalid geometries repaired.\n')
  } else {
    cat('Invalid geometries remaining:\n')
    print(report_clean%>% dplyr::select(-type, -valid, -error_msg))
  }

  poly_wdpa_bc <- poly_wdpa_bc_clean
} else {
  cat('No invalid geometries in BC WDPA SpatialPolygonsDataFrame.\n')
}

```

### Set up buffers and base raster

Buffer files are located in `github/ohibc/regions`.  LSP uses 1 km inland and 3nm offshore buffers.  The base raster will be used to rasterize the WDPA SPDataFrame in a later step, but the extents and projection need to match the extents and projections of the buffers.

* Read in buffer shapefiles to SpatialPolygonsDataFrames
* Create a region list of buffers and WDPA-MPA SpatialPolygonsDataFrames
* From these objects, get the extents and CRS (proj4string)
* Create a base raster from extents, CRS, and resolution.

```{r set up base raster, echo = FALSE, eval = TRUE}
lyr_3nm <- 'ohibc_offshore_3nm'
lyr_1km <- 'ohibc_inland_1km'

poly_3nm <- readOGR(dsn = path.expand(dir_rgn), layer = lyr_3nm, 
                    stringsAsFactors = FALSE, verbose = FALSE)
poly_1km <- readOGR(dsn = path.expand(dir_rgn), layer = lyr_1km, 
                    stringsAsFactors = FALSE, verbose = FALSE)

### provenance check:
lsp_git_prov(sprintf('%s/%s.shp', path.expand(dir_rgn), lyr_3nm))
lsp_git_prov(sprintf('%s/%s.shp', path.expand(dir_rgn), lyr_1km))

### polygon geometry validity check:
inval <- gIsValid(poly_3nm, byid = TRUE)
if(any(!inval)) cat(sprintf('Invalid geometries detected in %s\n', lyr_3nm))
inval <- gIsValid(poly_1km, byid = TRUE)
if(any(!inval)) cat(sprintf('Invalid geometries detected in %s\n', lyr_1km))

### create region list for lsp_get_extents and lsp_get_p4s functions
rgn_list <- list(poly_3nm, poly_1km, poly_wdpa_bc)

ext_rgn <- lsp_get_extents(rgn_list)
p4s_rgn <- lsp_get_p4s(rgn_list)

reso <- 500 ### resolution for all rasters in this process

base_raster <- lsp_get_base_raster(ext = ext_rgn, reso = reso, p4s_base = p4s_rgn, fn = NULL)

```

``` {r plot polygons, echo = TRUE, eval = TRUE, cache = TRUE}

plot(poly_3nm,     col = rgb(.4, .4,  1,  1), border = NA)
plot(poly_1km,     col = rgb( 0, .5,  0,  1), border = NA, add = TRUE)
plot(poly_wdpa_bc, col = rgb( 1, .5, .5, .5), border = NA, add = TRUE)

```

``` {r rasterize buffer polygons, echo = FALSE, eval = FALSE}
### (old: Convert inland 1 km and offshore 3nm polygons to rasters)

### Note: buffers are used as polygons, rather than rasters, in final analysis... this is just for reference...

# Create rasters for regions in BC Albers projection (no reprojection):
# rast_3nm <- gdal_rasterize(src_datasource = file.path(dir_rgn, 'ohibc_offshore_3nm.shp'), dst_filename = file.path(dir_rst, 'rast_offshore_3nm.tif'), 
#                                 a = 'rgn_id', a_nodata = NA,
#                                 te = c(ext_rgn@xmin, ext_rgn@ymin, ext_rgn@xmax, ext_rgn@ymax), tr = c(reso, reso), # extents and resolution for x and y
#                                 output_Raster = TRUE, # return output as a RasterBrick? 
#                                 ignore.full_scan = TRUE,
#                                 verbose = TRUE)
# rast_1km <- gdal_rasterize(src_datasource = file.path(dir_rgn, 'ohibc_inland_1km.shp'), dst_filename = file.path(dir_rst, 'rast_inland_1km.tif'), 
#                                 a = 'rgn_id', a_nodata = NA,
#                                 te = c(ext_rgn@xmin, ext_rgn@ymin, ext_rgn@xmax, ext_rgn@ymax), tr = c(reso, reso), # extents and resolution for x and y
#                                 output_Raster = TRUE, # return output as a RasterBrick? 
#                                 ignore.full_scan = TRUE,
#                                 verbose = TRUE)
### Raster::extract requires raster layers rather than raster bricks.  Unstack
### the raster bricks and select the first element in each resulting list.
# rast_3nm <- unstack(rast_3nm)[[1]]
# rast_1km <- unstack(rast_1km)[[1]]
# 
# plot(rast_3nm)
# plot(rast_1km, add = TRUE)

```

### Rasterize the BC WDPA-MPA shapefile

``` {r rasterize BC WDPA, echo = TRUE, eval = TRUE}
rast_wdpa_bc <- rasterize(poly_wdpa_bc, base_raster, field = 'STATUS_YR', fun = 'min', background = NA, 
                          filename = file.path(dir_rst, 'rast_wdpa_bc.tif'), overwrite = TRUE)
```

``` {r plot raster, echo = TRUE, eval = TRUE, cache = TRUE}
plot(poly_3nm,     col = rgb(.4, .4,  1,  1), border = NA)
plot(poly_1km,     col = rgb( 0, .5,  0,  1), border = NA, add = TRUE)

rast_cols = (colorRampPalette(brewer.pal(9, 'Reds'))(255)) # rainbow color scheme

plot(rast_wdpa_bc, col = rast_cols, alpha = 0.5, add = TRUE)
```

### Extract WDPA values against buffer regions

Extract the rasterized WDPA against the spatial polygons of the buffer regions.  Result is a list of raster cells within each region, and the associated WDPA value (earliest `STATUS_YR`) for that cell.

``` {r extract WDPA against buffers, echo = TRUE, eval = TRUE}
prot_mar_list <- raster::extract(rast_wdpa_bc, poly_3nm)
names(prot_mar_list) <- poly_3nm@data$rgn_id
prot_mar_df <- lsp_sum_prot_areas(prot_mar_list, reso = res(rast_wdpa_bc)[1])
### note: pull the resolution from the rast_wdpa_bc raster; 
### assume x and y resolution are identical

prot_ter_list <- raster::extract(rast_wdpa_bc, poly_1km)
names(prot_ter_list) <- poly_1km@data$rgn_id
prot_ter_df <- lsp_sum_prot_areas(prot_ter_list, reso = res(rast_wdpa_bc)[1])
```

### Calc status for each region for each year

Eventually this may move to an OHIBC version of `functions.R`, but for now will just calculate directly here.

``` {r calc status, eval = TRUE, echo = TRUE}

ref_pt = .3

prot_mar_df <- prot_mar_df %>%
  mutate(status = (cum_a_km2/tot_a_km2)/ref_pt*100,
         status = ifelse(status > 100, 100, status))

prot_ter_df <- prot_ter_df %>%
  mutate(status = (cum_a_km2/tot_a_km2)/ref_pt*100,
         status = ifelse(status > 100, 100, status))

lsp_status <- prot_mar_df %>% 
  dplyr::select(rgn_id, year, mar_status = status) %>%
  left_join(prot_ter_df %>% 
              dplyr::select(rgn_id, year, ter_status = status),
            by = c('rgn_id', 'year')) %>%
  mutate(status = (mar_status + ter_status) / 2)

write_csv(lsp_status, file.path(dir_bc, '/lsp/data/status.csv'))
  
```

### Plot map of status by region

Currently, the Lasting Special Places goal model is identical to the OHI Global model: a region's status is based upon percent of protected area within 1 km inland buffer and percent of protected area within 3 nautical mile offshore buffer, compared to a reference point of 30% protected area.

$$X_{LSP} = \frac{\frac{pA_{CMPA}}{pA_{refCMPA}} + \frac{pA_{CP}}{pA_{refCP}}}{2}$$

*pA* = percent of area within the inland or offshore buffer; *CMPA* = coastal marine protected area (3nm offshore); *CP* = coastline protected (1km inland); and *refCMPA* = *refCP* = 30% reference point for both measures.

Examining OHIBC Lasting Special Places scores for 1995 and 2015:
``` {r plot scores as polygons, eval = TRUE, echo = FALSE, message = FALSE, cache = TRUE}
source(file.path(dir_bc, 'R/poly_plot_scores.R'))
score_df_1995 <- lsp_status %>% 
  filter(year == 1995) %>% 
  rename(score = status)
print(score_df_1995)

poly_plot_scores(score_df_1995, scale_label = 'LSP Status', title = 'OHIBC LSP Status 1995')

score_df_2005 <- lsp_status %>% 
  filter(year == 2005) %>% 
  rename(score = status)
print(score_df_2005)

poly_plot_scores(score_df_2005, scale_label = 'LSP Status', title = 'OHIBC LSP Status 2005')

score_df_2015 <- lsp_status %>% 
  filter(year == 2015) %>% 
  rename(score = status)
print(score_df_2015)

poly_plot_scores(score_df_2015, scale_label = 'LSP Status', title = 'OHIBC LSP Status 2015')

```