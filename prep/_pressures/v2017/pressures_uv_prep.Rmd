---
title: 'OHIBC: Ultraviolet Anomalies Pressure layers prep'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    toc: true
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ohibc/src/templates/ohibc_hdr1.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = FALSE, message = FALSE, warning = FALSE)

library(sp)        # the classes and methods that make up spatial ops in R
library(rgdal)
library(raster)

dir_git <- '~/github/ohibc'
source(file.path(dir_git, 'src/R/common.R'))
  ### an OHIBC specific version of common.R

dir_anx     <- file.path(dir_M, 'git-annex/bcprep')
dir_spatial <- file.path(dir_git, 'prep/_spatial')  ### github: general buffer region shapefiles

### goal specific folders and info
goal      <- '_pressures'
scenario  <- 'v2017'
dir_goal  <- file.path(dir_git, 'prep', goal, scenario)
dir_goal_anx <- file.path(dir_anx, goal, scenario)

### provenance tracking
library(provRmd)
prov_setup()

### goal-specific source scripts
source(file.path(dir_goal, 'pressures_lyr_fxns.R'))

### other support functions
source(file.path(dir_git, 'src/R/rast_tools.R'))

reload <- FALSE

```

# Summary

For Global OHI 2017: 

>the Ultraviolet Radiation pressure layer is generated from daily data on Local Noon Erythemal UV Irradiance (mW/m2) derived from satellite observations. 

>1. Average the data for each week/year/cell  
>2. For each week/year/cell, calculate the mean and sd, so each cell would have ~624 (12*52) values (2004-2016)  
>3. Determine which of these were anomalous, defined as greater than the mean plus 1 standard deviation  
>4. Sum weekly anomalies for each year/cell (for a total of 52 possible anomalies per year/cell)  
>5. Calculate the total number of anomalies in the reference period (in our case, 2004-2009, for a total of 52*5 anomalies per cell)  
>6. Calculate the total number of anomalies in the most recent 5 year period (2011-2015)    
>7. then for each cell, get the difference between current anomalies and reference anomolies    
>8. Rescale the data to be between 0-1 by using the 99.99th quantile as a reference point

For OHIBC, we will use the global prepared data from steps 1-4, then clip to BC regions, interpolate to fill gaps, resample to OHIBC, and determine the pressure based on a reference point of 50% of weeks being higher than the climatological norms (mean + 1 standard deviation).  This 50% reference point represents a threshold to a "new normal" or a regime shift.

-----

# Data Source

* __Reference__: The Ultraviolet Radiation pressures layer uses the [Aura OMI GLobal Surface UVB Data Product](http://disc.sci.gsfc.nasa.gov/Aura/data-holdings/OMI/omuvbd_v003.shtml).  
* __Native Data Resolution__: 1 degree  
* __Values__: Level-3 OMI Surface UV Irradiance and Erythemal Dose- OMUVBd  
* __Time Range__: Daily data from 2005 - 2016 
* __Format__: HDF5  

__Note__: The first two weeks of June are missing from the 2016 raw data. The code is written in a way to account for this, but it does mean that we are missing two weeks that could slightly influence the results of the most recent pressure layer if it were available.

-----
  
# Methods  

## Preparing the raw data

These steps are completed in the OHI Global 2017 UV pressures data prep script.  They are briefly outlined here for clarity.

### Create rasters from HDF files

Calculate weekly means and standard deviations across all years

* List all files from raw data folder (`git-annex/globalprep/_raw_data/NASA_OMI_AURA_UV`)
* For every week in each year in the time series, calculate the weekly mean and standard deviation.
* Get weekly climatologies (mean and standard deviation of UV irradiance for each cell) across all years in the time series

### Compare mean UV irradiance to climatology

Compare each week in each year to the climatology for that week. The climatology is equal to the mean plus one standard deviation.  The result is a set of annual rasters of anomalous weeks for the year within that cell.

* These files can be found in `github/ohiprep/globalprep/prs_uv/v2017/int', filenames 'annual_pos_anomalies_XXXX.tif` where `XXXX` is the year.

## Collect data and localize to BC

Here we part ways with the global analysis.  Each layer is reprojected to BC Albers at 1000 m resolution (and cropped to BC extents).  These will be saved on Github.

``` {r localize_global_uv_data}

uv_global_data_dir <- '~/github/ohiprep/globalprep/prs_uv/v2017/int'
uv_pos_anom_files <- list.files(uv_global_data_dir, pattern = 'pos_anomalies', full.names = TRUE)

yrs <- str_extract(basename(uv_pos_anom_files), '[0-9]{4}')

bc_dst_files <- file.path(dir_goal, 'uv_rasts', sprintf('uv_anom_wks_%s.tif', yrs))

if(!all(file.exists(bc_dst_files)) | reload) {

  uv_anom_stack <- stack(uv_pos_anom_files)
  
  rast_base <- raster(file.path(dir_spatial, 'raster/ohibc_rgn_raster_1000m.tif'))
  
  bc_uv_stack <- uv_anom_stack %>%
    projectRaster(rast_base, method = 'ngb')
  
  bc_uv_stack_masked <- bc_uv_stack %>%
    mask(rast_base)
  
  writeRaster(bc_uv_stack_masked, bc_dst_files, bylayer = TRUE, overwrite = TRUE)
  
} else {
  git_prov(uv_pos_anom_files, filetype = 'input')
  git_prov(bc_dst_files, filetype = 'output')
}

```

## Calculate pressures from count of anomalous weeks

Each cell will be rescaled to a 0-1 score based on the reference point of 50% of weeks being anomalous.  Note for 2016, we have to account for two missing weeks, so we multiply the proportion of anomalous weeks by 26/25.

``` {r rescale_uv_pressures}

uv_anom_wks_files <- list.files(file.path(dir_goal, 'uv_rasts'),
                                pattern = 'uv_anom_wks', 
                                full.names = TRUE)

uv_anom_wks_stack <- stack(uv_anom_wks_files)

uv_prs_stack <- uv_anom_wks_stack / 26
uv_prs_stack[['uv_anom_wks_2016']] <- uv_prs_stack[['uv_anom_wks_2016']] * 26/25
  ### 2016 is missing two weeks; so values are based on 50 wks instead of 52.
  ### Adjust accordingly.

uv_prs_files <- uv_anom_wks_files %>%
  str_replace('uv_anom_wks', 'uv_prs')
writeRaster(uv_prs_stack, uv_prs_files, bylayer = TRUE, overwrite = TRUE)


```

To calculate region scores, we run zonal statistics on each layer to calculate a mean proportion of anomalous weeks over the entire region.  At that point we can apply a rolling mean as well, though this reduces our data availability for the earlier portion of our time frame.

``` {r calc_rgn_means}

uv_prs_files <- list.files(file.path(dir_goal, 'uv_rasts'),
                                pattern = 'uv_prs', 
                                full.names = TRUE)

uv_prs_stack <- stack(uv_prs_files)

ohibc_rgn_rast <- raster(file.path(dir_spatial, 'raster/ohibc_rgn_raster_1000m.tif'))

ohibc_rgn_uv <- zonal(uv_prs_stack, ohibc_rgn_rast, fun = 'mean', na.rm = TRUE) %>%
  as.data.frame() %>%
  rename(rgn_id = zone) %>%
  gather(year, prs_raw, -rgn_id) %>%
  group_by(rgn_id) %>%
  mutate(year = str_extract(year, '[0-9]{4}') %>%
           as.integer(),
         pressure = zoo::rollmean(prs_raw, 5, align = 'right', fill = NA))

write_csv(ohibc_rgn_uv, file.path(dir_goal, 'output/prs_uv_layer.csv'))

DT::datatable(ohibc_rgn_uv)

```

``` {r plot_pressures}

prs_df <- read_csv(file.path(dir_goal, 'output', 'prs_uv_layer.csv')) %>%
  left_join(get_rgn_names(), by = 'rgn_id')

prs_plot <- ggplot(prs_df, aes(x = year, y = pressure, color = rgn_name, group = rgn_name)) +
  ggtheme_plot() +
  geom_line(show.legend = FALSE, size = 1.5) +
  geom_line(show.legend = FALSE, aes(y = prs_raw), alpha = .4) +
  scale_color_brewer(palette = 'Dark2') +
  ylim(0, NA) +
  facet_wrap( ~ rgn_name) +
  labs(title = 'Ultraviolet Radiation pressure',
       x = 'Year',
       y = 'Rescaled pressure score')

print(prs_plot)

```

-----

# Citation information  

Jari Hovila, Antii Arola, and Johanna Tamminen (Oct ), OMI/Aura Surface UVB Irradiance and Erythemal Dose Daily L3 Global 1.0x1.0 deg Grid, version 003, NASA Goddard Space Flight Center
-----

``` {r provenance, results = 'asis'}
prov_wrapup(commit_outputs = FALSE)
```
