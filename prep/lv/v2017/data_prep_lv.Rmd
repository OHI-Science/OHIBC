---
title: 'OHIBC data prep: Livelihoods'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ohibc/src/templates/ohibc_hdr1.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)

library(sf)

source('~/github/ohibc/src/R/common.R')  ### an OHIBC specific version of common.R

scenario <- 'v2017'
goal     <- 'lv'
dir_git  <- '~/github/ohibc'
dir_goal <- file.path(dir_git, 'prep', goal, scenario)
dir_spatial <- file.path(dir_git, 'prep/_spatial')

dir_goal_anx <- file.path(dir_M, 'git-annex/bcprep', goal, scenario) 
dir_data_anx <- file.path(dir_M, 'git-annex/bcprep', '_raw_data')

library(provRmd); prov_setup()

### set up proj4string options: BC Albers and WGS84
p4s_bcalb <- c('bcalb' = '+init=epsg:3005')
p4s_wgs84 <- c('wgs84' = '+init=epsg:4326')

```

# Summary: OHIBC Livelihoods

This script prepares layers (employment rates and median income) for Livelihoods goal in 
British Columbia's coastal regions.  

From Halpern et al. (2014) (OHI California Current):

>Livelihood sub-goal: As was done in the global analysis, coastal livelihoods is measured by two equally weighted sub-components, the number of jobs (j), which is a proxy for livelihood quantity, and the median annual household wages (g), which is a proxy for job quality. For jobs and wages we used a no-net loss reference point. 

For British Columbia, we do not currently have sector-specific unemployment and wage information.  As such we will analyze Livelihoods according to the model:

$x_{LIV} = \frac{j' + g'}{2}$

$j' = \frac{j_c / j_{ref}}{M_c / M_{ref}}$

where M is each region’s employment rate (1 - unemployment) as a percent at current (c) and reference (ref) time periods, and:

$g' = \frac{g_c / g_{ref}}{W_c / W_{ref}}$

where W is each region’s average annual per capita wage at current (c) and reference (ref) time periods.

-----

# Data

__Census subdivision administrative boundaries__

* __Reference__: [Copyright © 2017, Province of British Columbia](http://www2.gov.bc.ca/gov/content/home/copyright)
* __Downloaded__: Aug 7, 2017 from:
    * http://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/bound-limit-2016-eng.cfm (2016 census subdivisions)
    * http://www2.gov.bc.ca/gov/content/data/geographic-data-services/land-use/administrative-boundaries (2011 census subdivisions)
    * http://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/bound-limit-2006-eng.cfm (2006 census subdivisions)
    * http://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/bound-limit-2001-eng.cfm (2001 census subdivisions)
* __Description__:  Census subdivision administrative boundaries; choose "English", "ArcGIS" (or "ARC/INFO" for 2001), census subdivisions, cartographic boundary file option)
* __Native data resolution__: Census subdivision
* __Format__:  ESRI shapefile (or Arc e00 file for 2001)

__2001, 2006, 2011, and 2016 Census Total Population Results by Census Subdivision__

* __Reference__: [Statistics Canada, Prepared by:  BC Stats, Ministry of Technology, Innovation and Citizens' Services]
* __Downloaded__: Aug 7, 2017 from 
    * http://www.bcstats.gov.bc.ca/StatisticsBySubject/Census/2001Census/PopulationHousing/CensusSubdivisions.aspx (2001)
    * http://www.bcstats.gov.bc.ca/StatisticsBySubject/Census/2006Census/PopulationHousing/CensusSubdivisions.aspx (2006)
    * http://www.bcstats.gov.bc.ca/StatisticsBySubject/Census/2011Census/PopulationHousing/CensusSubdivisions.aspx (2011) 
    * http://www.bcstats.gov.bc.ca/StatisticsBySubject/Census/2016Census/PopulationHousing/CensusSubdivisions.aspx (2016)
* __Description__:  Census subdivision populations for 2001, 2006, 2011, 2016
* __Native data resolution__: Census subdivision (note boundaries are different each year, use proper shapefile)
* __Format__:  .csv

__1996, 2001, 2006, 2011, and 2016 Census Income by Census Subdivision__

for 1996: download census profile as SDMX here:
http://www12.statcan.gc.ca/datasets/Alternative.cfm?PID=35782&EXT=SDMX

For 2001: download entire census profile as .csv here:
http://www12.statcan.gc.ca/census-recensement/2011/dp-pd/prof/index.cfm?Lang=E

For 2006, 2011, 2016: use `cancensus` package to retrieve data from CensusMapper API

-----

# Methods

## Apportion population of BC census subdivisions to OHIBC regions

Using the same methods from Clean Waters/Pathogens layer, extract population data per census subdivision (CSD) for each census year 2001-2006-2011-2016; combine to region level.

### Identify CSDs per OHIBC region

First determine allocation of CSDs to OHIBC regions by area.  The following chunk creates a dataframe combining all the CSDs in all the OHIBC regions (unclipped inland areas) for each year; note that the CSD boundaries change year to year.

The result is a dataframe with the following columns:

* csduid
* csdname
* csdtype
* rgn_id
* area_total_km2
* area_ohibc_km2
* prop_area
* year

``` {r figure_out_csd_by_year}

ohibc_rgn <- read_sf(dsn = dir_spatial,
                     layer = 'ohibc_rgns_unclipped')

csd_clean <- function(csd_sf, year) {
  csd_sf2 <- csd_sf %>%
    clean_df_names() %>%
    select(csduid, csdname, csdtype, geometry) %>%
    st_transform(st_crs(ohibc_rgn))
  
  csd_sf2$a_tot <- st_area(csd_sf)
  
  csd_sf_bc <- csd_sf2 %>%
    st_buffer(dist = 0) %>%
    st_intersection(ohibc_rgn) 
  
  csd_sf_bc$a_ohibc <- st_area(csd_sf_bc)
  
  csd_bc_df <- csd_sf_bc %>%
    as.data.frame() %>%
    clean_df_names()  %>%
    mutate(prop_area = as.numeric(a_ohibc / a_tot),
           area_total_km2 = as.numeric(a_tot / 1e6),
           area_ohibc_km2 = as.numeric(a_ohibc / 1e6),
           year = year) %>%
    select(csduid, csdname, csdtype, rgn_id, 
           area_total_km2, area_ohibc_km2, prop_area, year)
  
  return(csd_bc_df)
}

csd_info_file <- file.path(dir_goal, 'int/csd_2001-2016.csv')

if(!file.exists(csd_info_file)) {
  
  csd_2016 <- read_sf(dsn = file.path(dir_data_anx, 'bcstats/csd2016carto'),
                      layer = 'lcsd000b16a_e') %>%
    csd_clean(2016)
  
  csd_2011 <- read_sf(dsn = file.path(dir_data_anx, 'bcstats/csd2011carto'),
                      layer = 'gcsd000b11a_e') %>%
    csd_clean(2011)
  
  csd_2006 <- read_sf(dsn = file.path(dir_data_anx, 'bcstats/csd2006carto'),
                      layer = 'gcsd000b06a_e') %>%
    csd_clean(2006)
  
  csd_2001 <- read_sf(dsn = file.path(dir_data_anx, 'bcstats/csd2001carto_e00'),
                      layer = 'csd2001carto_from_e00_dissolved') %>%
    csd_clean(2001)

  csd_2001_2016 <- bind_rows(csd_2001, csd_2006, csd_2011, csd_2016) %>%
    distinct()
  
  write_csv(csd_2001_2016, csd_info_file)

} else {
  git_prov(csd_info_file, filetype = 'output')
}

```



### Identify populations per CSD

Using census data from each year, we can allocate populations to each of the CSDs contained in OHIBC regions.  Currently this uses population data from BC Stats, though the census datasets downloaded directly from Census Canada (from which we will get income and employment data) should have the same information.

``` {r read_pop_data_2001-2016}

pop_2016 <- read_csv(file.path(dir_data_anx, 'bcstats',
                               '2016 Census - CSD_control_79d4a796-2ccd-4732-a01c-1a8fd26d254a_1.csv')) %>%
  clean_df_names() %>%
  select(sgc, name, type, 
         pop = `2016_population`, 
         prev_pop = `2011_population_2`) %>%
  mutate(year = 2016)

pop_2011 <- read_csv(file.path(dir_data_anx, 'bcstats',
                               'Census 2011 Table6_5cb2908c-3bb5-4d64-b47e-a667a478c81f_3.csv')) %>%
  clean_df_names() %>%
  select(sgc, name, type, 
         pop = `2011_population`, 
         prev_pop = `2006_population_2`) %>%
  mutate(year = 2011)

pop_2006 <- read_csv(file.path(dir_data_anx, 'bcstats',
                               'Census 2006 Table4 CSD by Geo_3974fc9d-a861-42a2-94df-39ef3aa9b641_1.csv')) %>%
  clean_df_names() %>%
  select(sgc, name, type, 
         pop = `2006_population`, 
         prev_pop = `2001_population`) %>%
  mutate(year = 2006)

pop_2001 <- read_csv(file.path(dir_data_anx, 'bcstats',
                               'Census 2001 Table 4 - CSD_80e3912f-a235-46df-8ff0-c8afd0017122_1.csv')) %>%
  clean_df_names() %>%
  select(sgc, name, type,
         pop = `2001_population`,
         prev_pop = `1996_population_2`) %>%
  mutate(year = 2001)

pop_01_16 <- bind_rows(pop_2001, pop_2006, pop_2011, pop_2016) %>%
  distinct() %>%
  mutate(type = ifelse(str_detect(type, '^S-'), 'S-E', type))
    ### This last bit to clear up some UTF encoding issues

write_csv(pop_01_16, file.path(dir_goal, 'int/pop_2001-2016.csv'))

```

### Combine CSD-to-rgn lookup with pop-to-CSD lookup

Note that we can get the 1996 populations as well, using the prev_pop info from 2001, and assuming these numbers apply to the same 2001 census boundaries.

In this part we will collapse the "type" columns to divide CSDs into First Nations and non-First Nations districts; we also drop the Aristazabal Island region, considering it essentially unpopulated.

These can be identified from the census data using the "type" codes (and an older code of "R" used pre-2006 aligns with these First Nations as well): 

|CSD type | Description |
| :-----: | :---------- |
|   CY    | City |
|   DM    | District Municipality |
|    T    | Town |
|   VL    | Village |
|   IM    | Island Municipality |
|  IRI ✓  | Indian Reserve |
|  RDA    | Regional District Electoral Area |
|  IGD ✓  | Indian Governmental District |
|  S-E ✓  | Indian Settlement |
|   NL ✓  | Nisga'a Land |
|  NVL ✓  | Nisga'a Village |

``` {r census_pops_2001_2016}

pop_df <- read_csv(file.path(dir_goal, 'int/pop_2001-2016.csv'))

pop_1996 <- pop_df %>%
  filter(year == 2001) %>%
  select(-pop, pop = prev_pop) %>%
  mutate(year = 1996)

pop_df_incl_96 <- pop_df %>%
  bind_rows(pop_1996) %>%
  arrange(year) %>%
  select(-prev_pop)

csd_df <- read_csv(file.path(dir_goal, 'int/csd_2001-2016.csv')) 

csd_1996 <- csd_df %>%
  filter(year == 2001) %>%
  mutate(year = 1996)

csd_df_incl_96 <- csd_df %>%
  bind_rows(csd_1996)

fn_types <- c('IRI', 'IGD', 'S-E', 'NL', 'NVL', 'R')
  ### 'R' is an older code

pop_csd <- pop_df_incl_96 %>%
  left_join(csd_df_incl_96, by = c('sgc' = 'csduid', 'year', 'type' = 'csdtype')) %>%
  filter(!is.na(rgn_id)) %>%
  filter(rgn_id != 8) %>%
  mutate(fn = (type %in% fn_types)) %>%
  mutate(ohibc_pop = round(pop * prop_area)) %>%
  select(csd_id = sgc, type, name, year, ohibc_pop, fn, rgn_id) %>%
  filter(!is.na(ohibc_pop))

write_csv(pop_csd, file.path(dir_goal, 'int/pop_csd_yr.csv'))

```


## Read in census data on income and employment rate

The R package `cancensus` provides census information for 2006, 2011, and 2016.  A comparison between the `cancensus` results and the downloaded data show consistency in both unemployment rate (see note below) and income, when comparing median total household income (as opposed to individual or family income!)

For consistency we will use the `cancensus` reported median household income results for 2006, 2011, and 2016.

Unemployment results are similar across all, though there are some large percentage discrepancies for some communities - note that these tend to be very small communities where a change in reporting for a few individuals may make a significant change in the percent unemployment.  We will use `cancensus` reported unemployment rates for 2006, 2011, and 2016.

### Census data 1996

1996 data are archived as SDMX.  Due to technical issues (file size limits), the file is unable to be read into R...

``` {r read_census_1996}

# income_empl_1996_file <- file.path(dir_goal, 'int/income_empl_1996.csv')
# census_1996_raw_file <- file.path(dir_goal, 'int/census_raw_1996.csv')
# 
# ### 1996 data are saved as a SDMX file for entire Canada
# census_1996_gen_file <- file.path(dir_data_anx, 'canada_census',
#                                '95F0181XDB96001', 'Generic_95F0181XDB96001.xml')
# census_1996_str_file <- file.path(dir_data_anx, 'canada_census',
#                                '95F0181XDB96001', 'Structure_95F0181XDB96001.xml')
# 
# census_xml <- XML::xmlParse(census_1996_gen_file)
# 
# xmltop = xmlRoot(census_xml) #gives content of root
# class(xmltop)#"XMLInternalElementNode" "XMLInternalNode" "XMLAbstractNode"
# xmlName(xmltop) #give name of node, PubmedArticleSet
# xmlSize(xmltop) #how many children in node, 19
# xmlName(xmltop[[1]]) #name of root's children
# 
# xmltop[[2]]
# 
# [c("attrlabl","attrdef","attrtype","attrdomv")]
#   attrlabl             attrdef attrtype                                             attrdomv
# 1   COUNTY County abbreviation     Text CClackamas CountyMMultnomah CountyWWashington County
# 
# if(!file.exists(census_1996_raw_file)) {
#
#   ### Seems like the 1996 census file in SDMX format is too large for R
#   ### to handle:
#   ### Error in readChar(file, file.info(file)$size) : invalid 'nchars' argument
#   ### - probably b/c size is 3.2 GB
#   # devtools::install_github("opensdmx/rsdmx")
#   census_1996_gen <- rsdmx::readSDMX(census_1996_gen_file, isURL = FALSE)
#   census_1996_str <- rsdmx::readSDMX(census_1996_str_file, isURL = FALSE)
#
#   ### get codelists from structure
#   cls <- slot(census_1996_str, "codelists")
#
#   ### get list of codelists
#   codelists <- sapply(slot(cls, "codelists"), function(x) slot(x, "id"))
#   # "CL_GEO"                 "CL_A16_HHTYPE_CFSTRUCT" "CL_HHINC_GRP"           "CL_OBS_STATUS"
#
#   ### get codelist
#   geo_codes <- as.data.frame(slot(census_1996_str, "codelists"),
#                                 codelistId = 'CL_GEO') %>%
#     setNames(c('geo', 'csd_name'))
#   char_codes <- as.data.frame(slot(census_1996_str, "codelists"),
#                                          codelistId = 'CL_A16_HHTYPE_CFSTRUCT') %>%
#     setNames(c('a16_hhtype_cfstruct', 'value_fr', 'characteristic')) %>%
#     select(-value_fr)
#
#   income_codes <- as.data.frame(slot(census_1996_str, "codelists"), codelistId = 'CL_HHINC_GRP') %>%
#     setNames(c('hhinc_grp', 'value_fr', 'income_type')) %>%
#     select(-value_fr)
#
#   codes4 <- as.data.frame(slot(census_1996_str, "codelists"), codelistId = codelists[4]) %>%
#     setNames(c(codelists[4], 'value_fr', 'value')) %>%
#     select(-value_fr) %>%
#     clean_df_names()
#
#   csd_info <- read_csv(file.path(dir_goal, 'int/csd_2001-2016.csv')) %>%
#     filter(year == 2001)
#
#   census_1996 <- census_1996_gen %>%
#     clean_df_names() %>%
#     left_join(geo_codes) %>%
#     left_join(char_codes) %>%
#     left_join(income_codes) %>%
#     select(geo_code = geo, csd_name, characteristic, income_type, year = obstime, value = obsvalue) %>%
#     mutate(geo_code = as.integer(geo_code)) %>%
#     filter(geo_code %in% csd_info$csduid)
#
#   write_csv(census_1996, census_1996_raw_file)
# } else {
#   git_prov(c(census_1996_gen_file, census_1996_str_file), filetype = 'input')
#   git_prov(census_1996_raw_file, filetype = 'output')
# }
#
# income_1996 <- read_csv(census_1996_raw_file) %>%
#   filter(str_detect(income_type, 'Median total income')) %>%
#   filter(str_detect(characteristic, 'Total - Household type'))
#
# write_csv(income_1996, income_1996_file)

source(file.path(dir_goal, 'get_96_data_from_sdmx.R'))

```

### Census data 2001

These data have observations for median total income (in various descriptions) and employment/unemployment rates.  These were downloaded from the Canada Census site.

``` {r read_census_2001}

census_2001_file <- file.path(dir_data_anx, 'canada_census',
                              '93F0053XIE-301-BC.csv')

census_2001 <- read_csv(census_2001_file, skip = 2) %>%
  clean_df_names() %>%
  select(geo_code, csd_name, topic, characteristic, total) %>%
  distinct() %>%
  mutate(year = 2001)
emp_inc_2001 <- census_2001 %>%
  filter(str_detect(tolower(characteristic), 'median household income.+all households|unemployment')) %>%
  rename(csd_id = geo_code)

write_csv(emp_inc_2001, file.path(dir_goal, 'int/inc_emp_01.csv'))

```

### Census data 2006-2016

These data are all collected from the CensusMapper API using the `cancensus` R package.  To work, you must have a CensusMapper API key.  Mine is currently stored on Mazu at `git-annex/bcprep/_raw_data/canada_census/censusmapper_api.txt`.

Fields used to collect data (note the census sampling rates):

* 2006:
    * `v_CA06_2000`: Census 2006; 20% data; Income; Households; All Households; 
      Income Stats; Median household income $
    * `v_CA06_582`: Census 2006; 20% data; Labour Force Activity; Population 15 
      years and over by labour force activity; Unemployment rate
* 2011:
    * `v_CA11N_2562`: CA 2011 NHS; Income; Households; Household income in 2010 
      of private households; Median household total income $
    * `v_CA11N_2008`: CA 2011 NHS; Work; Labour force status; Unemployment rate
* 2016:
    * `v_CA16_2397`: CA 2016 Census; 100% data; Income; Households; Total - Income 
      statistics in 2015 for private households by household size - 100% data; 
      Median total income of households in 2015 ($)
    * `v_CA16_5618`: CA 2016 Census; 25% Data; Work; Labour Force Status; Unemployment rate


``` {r read_census_2006_2011_2016}

library(cancensus)

api_key <- scan(file.path(dir_M, 'git-annex/bcprep/_raw_data/canada_census/censusmapper_api.txt'), 
                what = 'character')
options(cancensus.cache_path = file.path(dir_goal_anx, 'cancensus_cache'),
        cancensus.api_key = api_key)
use_cancensus_cache <- TRUE

### Gather 2006 data
# income_vecs <- cancensus::list_census_vectors('CA06') %>%
#   filter(str_detect(tolower(label), 'household') & str_detect(tolower(label), 'income'))
# unempl_vecs <- cancensus::list_census_vectors('CA06') %>%
#   filter(str_detect(tolower(label), 'unempl'))
inc_emp_2006_raw <- cancensus::get_census(dataset = 'CA06', 
                                      regions = list(PR = '59'),
                                      vectors = c('v_CA06_2000', 'v_CA06_582'),
                                      level = 'CSD',
                                      use_cache = use_cancensus_cache) 

inc_emp_2006 <- inc_emp_2006_raw %>%
  clean_df_names() %>%
  mutate(region_name = as.character(region_name),
         year = 2006) %>%
  select(csd_id = geouid, csd_name = region_name,
         year, area_sq_km, population,
         unempl_rate = contains('unempl'), med_income = contains('income'))

### Gather 2011 data
# income_vecs <- cancensus::list_census_vectors('CA11') %>%
#   filter(str_detect(tolower(label), 'household') & str_detect(tolower(label), 'income'))
# unempl_vecs <- cancensus::list_census_vectors('CA11') %>%
#   filter(str_detect(tolower(label), 'unempl'))
inc_emp_2011_raw <- cancensus::get_census(dataset = 'CA11', 
                                      regions = list(PR = '59'),
                                      vectors = c('v_CA11N_2562', 'v_CA11N_2008'),
                                      level = 'CSD',
                                      use_cache = use_cancensus_cache)
inc_emp_2011 <- inc_emp_2011_raw %>%
  clean_df_names() %>%
  mutate(region_name = as.character(region_name),
         year = 2011) %>%
  select(csd_id = geouid, csd_name = region_name,
         year, area_sq_km, population,
         unempl_rate = contains('unempl'), med_income = contains('income'))

# income_vecs <- cancensus::list_census_vectors('CA16') %>%
#   filter(str_detect(tolower(label), 'household') & str_detect(tolower(label), 'income'))
# unempl_vecs <- cancensus::list_census_vectors('CA16') %>%
#   filter(str_detect(tolower(label), 'unempl'))
inc_emp_2016_raw <- cancensus::get_census(dataset = 'CA16', 
                                      regions = list(PR = '59'),
                                      vectors = c('v_CA16_2397', 'v_CA16_5618'),
                                      level = 'CSD',
                                      use_cache = use_cancensus_cache)
inc_emp_2016 <- inc_emp_2016_raw %>%
  clean_df_names() %>%
  mutate(region_name = as.character(region_name),
         year = 2016) %>%
  select(csd_id = geouid, csd_name = region_name,
         year, area_sq_km, population,
         unempl_rate = contains('unempl'), med_income = contains('income'))

inc_emp_06_11_16 <- bind_rows(list(inc_emp_2006, inc_emp_2011, inc_emp_2016)) %>%
  mutate(csd_id = as.integer(csd_id))

write_csv(inc_emp_06_11_16, file.path(dir_goal, 'int/inc_emp_06_11_16.csv'))

```

### Combine 1996 and 2001 with 2006/2011/2016

Also adjust income by CPI to 2016 dollars.  Median income for data years are adjusted for inflation based on CPI (manually pulled data): http://www.statcan.gc.ca/pub/62-001-x/2017001/t040-eng.htm which is then used to approximate earlier years (1996-1997) and then adjusted to 2016 dollars.

``` {r fix_cpi_data}

### manually bring in CPI using data from 1998-2016; manually fill for 1996-1997
cpi_raw <- read_csv(file.path(dir_goal, 'raw/can_cpi.csv')) %>%
  select(year, cpi = annual_avg)

cpi_trend <- lm(cpi ~ year, cpi_raw)[['coefficients']]['year'] ### 2.095 per year overall average

earliest_cpi <- cpi_raw %>%
  filter(year == min(year))

cpi <- cpi_raw %>%
  bind_rows(data.frame(year = c(1996, 1997),
                       cpi  = c(NA, NA))) %>%
  arrange(year) %>%
  mutate(lag_yr = ifelse(is.na(cpi), min(cpi_raw$year) - year, NA),
         cpi = ifelse(is.na(cpi), earliest_cpi$cpi - lag_yr * cpi_trend, cpi)) %>%
  mutate(cpi = 100 * cpi / last(cpi)) %>%
  select(-lag_yr)

write_csv(cpi, file.path(dir_goal, 'int/can_cpi_1996_2016.csv'))
```

``` {r combine_2001-2016_data}

inc_emp_1996 <- read_csv(file.path(dir_goal, 'int/inc_emp_96.csv'))

inc_emp_2001 <- read_csv(file.path(dir_goal,  'int/inc_emp_01.csv')) %>%
  mutate(field = case_when(str_detect(characteristic, 'income')  ~  'med_income',
                           str_detect(characteristic, '^Unempl') ~ 'unempl_rate')) %>%
  select(csd_id, csd_name, field, value = total, year) %>%
  distinct()

inc_emp_06_11_16 <- read_csv(file.path(dir_goal, 'int/inc_emp_06_11_16.csv'),
                             col_types = 'icidddd') %>%
  gather(field, value, unempl_rate:med_income) %>%
  select(csd_id, csd_name, field, value, year) %>%
  distinct()

inc_empl_allyears <- bind_rows(inc_emp_1996, inc_emp_2001, inc_emp_06_11_16)

### Adjust incomes by CPI
cpi <- read_csv(file.path(dir_goal, 'int/can_cpi_1996_2016.csv'))

inc_empl_allyears_adj <- inc_empl_allyears %>%
  spread(field, value) %>%
  left_join(cpi, by = 'year') %>%
  mutate(adj_med_income = med_income * 100 / cpi)

write_csv(inc_empl_allyears_adj, file.path(dir_goal, 'int/inc_and_empl_yr_csd.csv'))

```

## Aggregate census data to OHIBC region by population weight

Income and employment values at census district level are aggregated to the OHIBC region level, using population weighting of each CD within each OHIBC region to determine a weighted mean of the median values in each district.

`NA` values for income or unemployment for specific CSDs are gapfilled using a regional average across that year and First Nations category.

Years between censuses are filled using linear interpolation.

### Income data

NOTE:  Some CSDs for some years show a zero median income for some years.  These CSDs will be excluded from the analysis for those years, as anomalous values.  In all cases the populations are very small (< 300 people).  In most cases, these are First Nations communities (164 out of 190 communities).  

``` {r calc_income_layer}
rgn_df <- read_csv(file.path(dir_goal, 'int', 'pop_csd_yr.csv')) 

### combine data with regions and drop NAs
income_df <- read_csv(file.path(dir_goal, 'int', 'inc_and_empl_yr_csd.csv')) %>%
  select(-csd_name, -med_income, -cpi) %>%
  left_join(rgn_df, by = c('csd_id', 'year')) %>%
  filter(ohibc_pop > 0 & adj_med_income > 0)

income_wt_med <- income_df %>%
  group_by(year, rgn_id) %>%
  mutate(rgn_med_adj = sum(adj_med_income * ohibc_pop, na.rm = TRUE) / sum(ohibc_pop)) %>%
  group_by(year, rgn_id, fn, rgn_med_adj) %>%
  summarize(cat_med_adj = sum(adj_med_income * ohibc_pop, na.rm = TRUE) / sum(ohibc_pop),
            category_pop  = sum(ohibc_pop, na.rm = TRUE)) %>%
  ungroup()

### Fill in intervening years
income_wt_med_allyrs <- income_wt_med %>%
  group_by(rgn_id, fn) %>%
  complete(year = min(year):max(year), nesting(rgn_id)) %>%
  mutate(rgn_med_adj = zoo::na.approx(rgn_med_adj, year),
         cat_med_adj = zoo::na.approx(cat_med_adj, year),
         category_pop   = zoo::na.approx(category_pop, year)) %>%
  ungroup() %>%
  mutate(rgn_med_adj = round(rgn_med_adj, 2),
         cat_med_adj = round(cat_med_adj, 2))

fn_income <- income_wt_med_allyrs %>%
  filter(fn) %>%
  select(year, rgn_id, med_adj_income = cat_med_adj)

non_fn_income <- income_wt_med_allyrs %>%
  filter(!fn) %>%
  select(year, rgn_id, med_adj_income = cat_med_adj)

# fn_pop_income <- income_wt_med_allyrs %>%
#   filter(fn) %>%
#   select(year, rgn_id, fn_pop = category_pop)
# 
# non_fn_pop_income <- income_wt_med_allyrs %>%
#   filter(!fn) %>%
#   select(year, rgn_id, non_fn_pop = category_pop)

write_csv(fn_income, file.path(dir_goal, 'output', 'lv_income_fn.csv'))
write_csv(non_fn_income, file.path(dir_goal, 'output', 'lv_income_nonfn.csv'))
# write_csv(fn_pop_income, file.path(dir_goal, 'int', 'lv_pop_income_fn.csv'))
# write_csv(non_fn_pop_income, file.path(dir_goal, 'int', 'lv_pop_income_nonfn.csv'))

DT::datatable(income_wt_med_allyrs, caption = 'Median income (2016 CAD)')

```

### Unemployment data

CSDs with zero reported unemployment for a given year are dropped from the analysis for that year as anomalous.  Nearly all these communities are small (200 or fewer), with a few larger communities up to 1176 pop. Of these, 82 out of 127 are First Nations communities.

``` {r calc_unemployment_layer}

rgn_df <- read_csv(file.path(dir_goal, 'int', 'pop_csd_yr.csv'))

### combine data with regions and gapfill NAs
unempl_df <- read_csv(file.path(dir_goal, 'int', 'inc_and_empl_yr_csd.csv')) %>%
  select(csd_id, year, unempl_rate) %>%
  left_join(rgn_df, by = c('csd_id', 'year')) %>%
  filter(ohibc_pop > 0) %>%
  filter(unempl_rate > 0 & !is.na(unempl_rate))

unempl_wt_mean <- unempl_df %>%
  group_by(year, rgn_id) %>%
  mutate(rgn_mean_unempl_all = sum(unempl_rate * ohibc_pop, na.rm = TRUE) / sum(ohibc_pop),
         rgn_mean_unempl_all = round(rgn_mean_unempl_all, 2)) %>%
  group_by(year, rgn_id, fn, rgn_mean_unempl_all) %>%
  summarize(cat_mean_unempl  = sum(unempl_rate * ohibc_pop, na.rm = TRUE) / sum(ohibc_pop),
            cat_mean_unempl  = round(cat_mean_unempl, 2),
            category_pop = sum(ohibc_pop, na.rm = TRUE)) %>%
  ungroup()

unempl_wt_mean_allyrs <- unempl_wt_mean %>%
  group_by(rgn_id, fn) %>%
  complete(year = min(year):max(year), nesting(rgn_id)) %>%
  mutate(rgn_mean_unempl_all = zoo::na.approx(rgn_mean_unempl_all, year),
         cat_mean_unempl     = zoo::na.approx(cat_mean_unempl, year),
         category_pop        = zoo::na.approx(category_pop, year)) %>%
  ungroup()

fn_unempl <- unempl_wt_mean_allyrs %>%
  filter(fn) %>%
  select(year, rgn_id, mean_unempl = cat_mean_unempl)

non_fn_unempl <- unempl_wt_mean_allyrs %>%
  filter(!fn) %>%
  select(year, rgn_id, mean_unempl = cat_mean_unempl)

# fn_pop_unempl <- unempl_wt_mean_allyrs %>%
#   filter(fn) %>%
#   select(year, rgn_id, fn_pop = category_pop)
# 
# non_fn_pop_unempl <- unempl_wt_mean_allyrs %>%
#   filter(!fn) %>%
#   select(year, rgn_id, non_fn_pop = category_pop)

write_csv(fn_unempl,         file.path(dir_goal, 'output', 'lv_unempl_fn.csv'))
write_csv(non_fn_unempl,     file.path(dir_goal, 'output', 'lv_unempl_nonfn.csv'))
# write_csv(fn_pop_unempl,     file.path(dir_goal, 'int', 'lv_pop_unempl_fn.csv'))
# write_csv(non_fn_pop_unempl, file.path(dir_goal, 'int', 'lv_pop_unempl_nonfn.csv'))

DT::datatable(unempl_wt_mean_allyrs, caption = 'Mean unemployment')

```


### Alternate lower-bound reference points

In a simple no-net-loss model, the top reference point is set at the rolling mean of the previous five year period (e.g. ref pt for 2009 is mean of 2004-2008 values), but currently assumes (implicitly) a lower reference point of 0.  This results in all scores being extremely close to 1: even a 10% decline below the reference point, essentially a large dip in income for all people, results in a score of 90.

Instead let's try a lower reference point based on the income at the bottom quantile (say 5% or 10%) of the population of each region, or the min value found in the region.  The score calculation would look like:

$$X_{wages} = \frac{I_{current} - I_{low.ref}}{I_{ref} - I_{low.ref}}$$

$$X_{jobs} = \frac{E_{current} - E_{low.ref}}{E_{ref} - E_{low.ref}}$$

though our data are expressed in unemployment, rather than employment; so more accurately, 

$$X_{jobs} = \frac{1 - U_{current} - (1 - U_{high.ref})}{1 - U_{ref} - (1 - U_{high.ref})} = \frac{U_{high.ref} - U_{current}}{U_{high.ref} - U_{ref}}$$

where $I,U$ represent median income and unemployment rate respectively, and $E = 1 - U$ represents the employment rate.

#### Lower reference point: income

Reference point will be calculated based on entire population of each region for each year, presuming that a low wage is equally bad for First Nations and non-First Nations.  CSDs with zero median income are dropped as anomalous.

As calculated here, we will use the minimum median income for any CSD (FN or otherwise, but probably FN) with a population of at least 100 (to establish some minimum community size for averaging).  Using the bottom decile resulted in median income floors that were in most cases higher than the mean for First Nations; largely due to differences in income, and compounded since the population of FN communities are much smaller than non-FN communities.

``` {r calc_income_ref_pts}

rgn_df <- read_csv(file.path(dir_goal, 'int', 'pop_csd_yr.csv'))

### combine data with regions and gapfill NAs
income_df <- read_csv(file.path(dir_goal, 'int', 'inc_and_empl_yr_csd.csv')) %>%
  select(csd_id, year, adj_med_income) %>%
  left_join(rgn_df, by = c('csd_id', 'year')) %>%
  filter(ohibc_pop > 0 & adj_med_income > 0)

### Order communities in each region/year by income;
### select the communities with population in the bottom 5%;
### take weighted mean of median incomes (clipping any pop above
### the quantile population)
# ref_quantile = .05
# 
# ref_pts_qtile <- income_df %>%
#   group_by(rgn_id, year) %>%
#   arrange(rgn_id, year, adj_med_income) %>%
#   mutate(cum_pop = cumsum(ohibc_pop),
#          qtile   = max(cum_pop) * ref_quantile) %>%
#   filter(lag(cum_pop) < qtile | cum_pop == first(cum_pop)) %>%
#     ### the OR accounts for the case where one community includes the bottom decile
#     ### in which case, lag returns NA
#   mutate(adj_pop = ifelse(cum_pop > qtile, qtile - lag(cum_pop), ohibc_pop),
#          adj_pop = ifelse(is.na(adj_pop), qtile, adj_pop)) %>%
#     ### the second line accounts for the case where one community includes the bottom decile
#   summarize(med_inc_qtile = sum(adj_med_income * adj_pop) / sum(adj_pop))

min_comm_size <- 100

ref_pts_min <- income_df %>%
  group_by(rgn_id, year) %>%
  filter(ohibc_pop >= min_comm_size) %>% 
  summarize(med_inc_min = min(adj_med_income))

ref_pts_low_allyrs <- ref_pts_min %>%
  group_by(rgn_id) %>%
  complete(year = min(year):max(year)) %>%
  mutate(income_lower_ref = zoo::na.approx(med_inc_min, year) %>% round())
  
write_csv(ref_pts_low_allyrs, file.path(dir_goal, 'output/lv_income_lower_ref.csv'))

```

#### Upper reference point: unemployment

Reference point will be calculated based on entire population of each region for each year, presuming that low employment is equally bad for First Nations and non-First Nations.  CSDs with zero reported unemployment for a given year are dropped for that year as anomalous.

As for median income, we will use as a reference point the max unemployment (i.e. minimum employment) for all communities within a region that meet some threshold population. 

``` {r calc_unempl_ref_pts}

rgn_df <- read_csv(file.path(dir_goal, 'int', 'pop_csd_yr.csv'))

### combine data with regions and gapfill NAs
unempl_df <- read_csv(file.path(dir_goal, 'int', 'inc_and_empl_yr_csd.csv')) %>%
  select(csd_id, year, unempl_rate) %>%
  left_join(rgn_df, by = c('csd_id', 'year')) %>%
  filter(ohibc_pop > 0) %>%
  filter(unempl_rate > 0 & !is.na(unempl_rate))

### Order communities in each region/year by income;
### cut out any communities below the 10th %ile, and take the
### next one in the line using first().
# ref_pts_qtile <- unempl_df %>%
#   group_by(rgn_id, year) %>%
#   arrange(rgn_id, year, desc(unempl_rate)) %>%
#   mutate(cum_pop = cumsum(ohibc_pop),
#          qtile  = max(cum_pop) * ref_quantile) %>%
#   filter(lag(cum_pop) < qtile | cum_pop == first(cum_pop)) %>%
#     ### the OR accounts for the case where one community includes the bottom qtile
#     ### in which case, lag returns NA
#   mutate(adj_pop = ifelse(cum_pop > qtile, qtile - lag(cum_pop), ohibc_pop),
#          adj_pop = ifelse(is.na(adj_pop), qtile, adj_pop)) %>%
#     ### The second line accounts for the case where one community includes the bottom qtile
#   summarize(unempl_qtile = sum(unempl_rate * adj_pop) / sum(adj_pop))

ref_pts_max <- unempl_df %>%
  group_by(rgn_id, year) %>%
  filter(ohibc_pop >= min_comm_size) %>%
  summarize(unempl_max = max(unempl_rate))

ref_pts_low_allyrs <- ref_pts_max %>%
  group_by(rgn_id) %>%
  complete(year = min(year):max(year)) %>%
  mutate(unempl_upper_ref = zoo::na.approx(unempl_max, year) %>% round(2))
  
write_csv(ref_pts_low_allyrs, file.path(dir_goal, 'output/lv_unempl_upper_ref.csv'))

```

#### Reference point discussion

In all cases, setting a non-zero lower bound reference point will far more harshly penalize scores for First Nations communities.  Using a bottom decile value for income and employment establish a lower-bound reference that in most cases exceeds the value for First Nations communities, resulting in a score of zero.  Even setting a reference point based on the minimum value within a region creates a reference point that is often barely lower than the region's overall value.  Without a doubt, First Nations communities throughout Canada are vastly underserved by the market economy: https://globalnews.ca/news/3795083/reserves-poverty-line-census/.

Wage reference points based on a poverty line or minimum wage value are complicated by the fact that we're looking at household income rather than individual; http://www.livingwageforfamilies.ca/tags/poverty_line_bc has some information on poverty in BC.  Employment reference points are tricky as well.

Due to these complications, it is probably best to stick with the simplest model, using a zero lower bound reference point as is typical of other OHI assessments.  

### Visualize

Solid lines indicate average income (population-weighted average of median income across all census subdistricts, for First Nations and non-First Nations).  Dashed line indicates a potential lower bound reference, determined by the median income of the CSD (with pop > 100) with the lowest median income.  Similar for unemployment, though the reference line is the maximum unemployment found in any CSD with pop > 100.

``` {r data_viz_unempl, eval = TRUE}

income_layer <- read_csv(file.path(dir_goal, 'output', 'lv_income_fn.csv')) %>%
  rename(income_fn = med_adj_income) %>%
  left_join(read_csv(file.path(dir_goal, 'output', 'lv_income_nonfn.csv')) %>%
              rename(income_non_fn = med_adj_income),
            by = c('rgn_id', 'year')) %>%
  left_join(get_rgn_names(), by = 'rgn_id') %>%
  gather(first_nations, median_income, contains('income')) %>%
  mutate(first_nations = !str_detect(first_nations, 'non_fn'))

# income_ref <- read_csv(file.path(dir_goal, 'output', 'lv_income_lower_ref.csv')) %>%
#   left_join(get_rgn_names(), by = 'rgn_id')

ggplot(income_layer, aes(x = year, y = median_income)) +
  ggtheme_plot() +
  geom_line(aes(group = first_nations, color = first_nations), alpha = .7, size = 1.5) +
  # geom_line(data = income_ref, aes(y = income_lower_ref, group = rgn_name),
  #           color = 'red', linetype = 'dashed') +
  scale_x_continuous(breaks = seq(1996, 2016, 5)) +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  scale_y_continuous(limits = c(0, NA)) +
  facet_wrap( ~ rgn_name)

```

``` {r data_viz_income, eval = TRUE}

unempl_layer <- read_csv(file.path(dir_goal, 'output', 'lv_unempl_fn.csv')) %>%
  rename(unempl_fn = mean_unempl) %>%
  left_join(read_csv(file.path(dir_goal, 'output', 'lv_unempl_nonfn.csv')) %>%
              rename(unempl_non_fn = mean_unempl),
            by = c('rgn_id', 'year')) %>%
  left_join(get_rgn_names(), by = 'rgn_id') %>%
  gather(first_nations, mean_unempl, contains('unempl')) %>%
  mutate(first_nations = !str_detect(first_nations, 'non_fn'))

# unempl_ref <- read_csv(file.path(dir_goal, 'output', 'lv_unempl_upper_ref.csv')) %>%
#   left_join(get_rgn_names(), by = 'rgn_id')

ggplot(unempl_layer, aes(x = year, y = mean_unempl, color = first_nations)) +
  ggtheme_plot() +
  geom_line(aes(group = first_nations), alpha = .7, size = 1.5) +
  # geom_line(data = unempl_ref, aes(y = unempl_upper_ref, group = rgn_name), 
  #           color = 'red', linetype = 'dashed') +
  scale_x_continuous(breaks = seq(1996, 2016, 5)) +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  scale_y_continuous(limits = c(0, NA)) +
  facet_wrap( ~ rgn_name)

```

-----

``` {r provenance, results = 'asis'}

prov_wrapup(commit_outputs = FALSE)

```
