---
title: 'OHIBC: data prep for wild-capture fisheries: Sea Around Us data'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ohibc/src/templates/ohibc_hdr1.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)

library(data.table)
library(seaaroundus) ### devtools::install_github("ropensci/seaaroundus")
library(raster)

dir_git <- '~/github/ohibc'
source(file.path(dir_git, 'src/R/common.R'))  ### an OHIBC specific version of common.R
dir_spatial <- path.expand(file.path(dir_git, 'prep/_spatial'))  ### github: general buffer region shapefiles
dir_anx     <- file.path(dir_M, 'git-annex/bcprep')


### goal specific folders and info
goal      <- 'fis'
scenario  <- 'v2017'
dir_goal  <- file.path(dir_git, 'prep', goal, scenario)
dir_goal_anx <- file.path(dir_anx, goal, scenario)

### provenance tracking
library(provRmd); prov_setup()

### set up proj4string options: BC Albers and WGS84
p4s_wgs84 <- '+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0'
p4s_bcalb <- '+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'


### some common files:
saup_bc_rast_file <- file.path(dir_goal, 'saup/2_saup_cells_rast.tif')

rgn_to_saup_file <- file.path(dir_goal, 'saup/2_rgn_to_saup_cells_ohibc.csv')

```

# Summary

Process Sea Around Us data for British Columbia, to determine spatial distribution of catch for each species in BC.  The catch levels are used to weight the scores for fisheries stock status scores.  Stock status will be determined using RAM data for B/Bmsy and F/Fmsy.

This script will identify OHIBC-relevant stocks included in SAUP and extracting cell-by-cell values of catch for these fisheries.  Further spatialization (in `3_data_prep_fis_spatial.Rmd`) will allocate SAUP catch to RAM stocks and OHIBC regions.

Within this script we will also create a SAUP cell to OHIBC region lookup table with area-weighted allocations of cells to regions.


***

# Data Source 

**Reference**: http://www.seaaroundus.org/

**Downloaded**: 2016

**Description**:  Cell-by-cell catch (reported/unreported, industrial/artisanal/subsistence/recreational, landings/discard) for species across time

**Native data resolution**: 0.5° x 0.5°

**Time range**: 1950 - 2010

**Format**:  .dat data file

***
  
# Methods

## Create SAUP cell to BC region lookup

Using BC EEZ region bounding box, determine SAUP cells within that rectangle.  Extract against OHIBC regions.  For cells in multiple regions, assign weight according to proportion of area in each region.  Assume that cells attributed to a single region fall entirely within that region (e.g. cells with weight less than 1 due to fjords or edge of EEZ are re-normalized to a weight of 1)

Apparently SAUP uses LOICZID cell IDs so cell borders should be on the .00 and .50... do not select cells with a window that is right on the borders, since inclusion or exclusion on the borders is not clear.

``` {r create_saup_bc_raster}

if(!file.exists(saup_bc_rast_file)) {
  ### Find cells for BC EEZ
  # bc_rgn <- readOGR(dir_spatial, 'ohibc_rgn') %>%
  #   spTransform(CRS('+init=epsg:4326'))
  # bbox(bc_rgn)
  # # min        max
  # # x -138.75908 -122.75493
  # # y   46.52686   55.93538
  xmin <- -138.75908; xmax <- -122.75493
  ymin <-   46.52686; ymax <-   55.93538
  
  bc_cells <- seaaroundus::getcells(sprintf('POLYGON ((%s %s, %s %s, %s %s, %s %s, %s %s))', 
                               xmin, ymin, xmin, ymax, xmax, ymax, xmax, ymin, xmin, ymin))
  
  
  ### Create raster of cell IDs
  saup_bc_rast   <- raster::raster(xmn = -139.0, xmx = -122.5, 
                                   ymn =   46.5, ymx =   56.0,
                                   resolution = .5)
  saup_bc_rast[] <- bc_cells
  writeRaster(saup_bc_rast, 
            saup_bc_rast_file, 
            overwrite = TRUE)
  
}
  
```

``` {r identify_bc_cells}

saup_bc_rast <- raster(saup_bc_rast_file)

if(!file.exists(rgn_to_saup_file)) {

  ### Find area of each cell by cell ID
  area_df <- area(saup_bc_rast) %>%
    crosstab(saup_bc_rast, digits = 2) %>%
    filter(Freq == 1) %>%
    dplyr::select(cell_id  = Var2,
                  area_km2 = Var1) %>%
    mutate(cell_id  = as.integer(as.character(cell_id)),
           area_km2 = as.numeric(as.character(area_km2)))
  
  ### Identify cells that fall within BC regions (BC EEZ only);
  ### extract to a list then bind to data frame.
  bc_rgn <- readOGR(dir_spatial, 'ohibc_rgn')
  
  rgn_to_saup_list <- raster::extract(saup_bc_rast, bc_rgn, 
                                       weights = TRUE,
                                       normalizeWeights = FALSE) %>%
    lapply(FUN = function(x) as.data.frame(x, stringsAsFactors = FALSE)) %>%
    setNames(bc_rgn@data$rgn_id)
  
  ### weight is how much of cell is in EEZ; but this also includes area
  ### lost to land, not just to other regions.  Normalize cell weights
  ### to total *ocean* area; then attach area dataframe.
  rgn_to_saup <- rgn_to_saup_list %>%
    bind_rows(.id = 'rgn_id') %>%
    rename(cell_id = value) %>%
    group_by(cell_id) %>%
    mutate(weight = weight / sum(weight)) %>%
    ungroup() %>%
    left_join(area_df, by = 'cell_id') %>%
    rename(ohibc_wt = weight)
  
  values(saup_bc_rast)[!values(saup_bc_rast) %in% rgn_to_saup$cell_id] <- NA
  write_csv(rgn_to_saup, rgn_to_saup_file)

} else {
  message('Region-to-SAUP-cell lookup already exists; ', rgn_to_saup_file)
  
  git_prov(rgn_to_saup_file, filetype = 'output')
}

```


## Pare SAUP data down to BC region

Load SAUP data: these are RDS files for each year, extracted by Jamie using the `seaaroundus` package, from the script at:

`Mazu:git-annex/globalprep/_raw_data/SAUP/d2017/annual_data/download_saup_data.R`

The data will be stored using IDs for fields rather than text, for smaller files and quicker loading.  We will create lookups for each of the ID fields to name fields.

Pare results down to just observations that fall within BC cells; then pare the allocation data to just these species.  Combine the two into a single dataset (along with taxonomic info) and save to git-annex.  We will import only years 1980-present (for time and file size).

#### Lookup tables:

``` {r create_lookups_for_saup_ids}

### Path to data files
dir_data <- file.path(dir_M, 'git-annex/globalprep/_raw_data/SAUP/d2017/annual_data')

rds_files <- list.files(dir_data, pattern = '.rds$', full.names = FALSE)

id_lookups <- c(
  'sector_type'      = file.path(dir_goal, 'saup/2_sector_type_ids.csv'),
  'functional_group' = file.path(dir_goal, 'saup/2_functional_group_ids.csv'),
  'fishing_entity'   = file.path(dir_goal, 'saup/2_fishing_entity_ids.csv'),
  'commercial_group' = file.path(dir_goal, 'saup/2_commercial_group_ids.csv'),
  'catch_status'     = file.path(dir_goal, 'saup/2_catch_status_ids.csv'),
  'reporting_status' = file.path(dir_goal, 'saup/2_reporting_status_ids.csv'))
  
reload <- FALSE

for(i in seq_along(id_lookups)) {
  
  lookup_name <- names(id_lookups)[i]
  
  if(!file.exists (lookup_name) | reload) {
    if(!exists('saup_x')) {
      message('Loading SAUP data from ', file.path(dir_data, rds_files[length(rds_files)]))
      saup_x <- readRDS(file.path(dir_data, rds_files[length(rds_files)]))
    }
    message('Processing ', lookup_name)
    
    lookup_cols <- names(saup_x)[str_detect(names(saup_x), lookup_name)]
    tmp_df <- saup_x[lookup_cols] %>%
      distinct() %>%
      arrange_(lookup_cols[1])
    
    write_csv(tmp_df, id_lookups[i])
  } else {
    message('Lookup for ', lookup_name, ' already exists.')
  }
}

lookups_list <- lapply(id_lookups, read_csv) %>%
  setNames(names(id_lookups))

for(i in seq_along(lookups_list)) {
  if (nrow(lookups_list[[i]]) > 10) {
    DT::datatable(lookups_list[[i]], caption = names(lookups_list)[i])
  } else {
    knitr::kable(lookups_list[[i]], caption = names(lookups_list)[i])
  }
}
```

### Load data by year

``` {r load_data_by_year}

ohibc_cells <- read_csv(rgn_to_saup_file) %>%
  .$cell_id %>%
  unique()

### Path to data files
dir_data <- file.path(dir_M, 'git-annex/globalprep/_raw_data/SAUP/d2017/annual_data')

rds_files <- list.files(dir_data, pattern = '.rds$', full.names = FALSE)

data_years <- 1980:2017

rds_yrs <- rds_files[str_detect(rds_files, paste(data_years, collapse = '|'))]

#  [1] "year"                  "sector_type_id"        "fishing_entity_id"     "commercial_group_name" "sector_type_name"     
#  [6] "taxon_scientific_name" "functional_group_name" "functional_group_id"   "catch_status_name"     "taxon_common_name"    
# [11] "cell_id"               "reporting_status_name" "fishing_entity_name"   "catch_sum"             "taxon_key"            
# [16] "commercial_group_id"   "catch_status"          "reporting_status"     

saup_raw_file <- file.path(dir_goal_anx, 'saup/2_saup_bc_raw.csv')

reload <- FALSE

if(!file.exists(saup_raw_file) | reload) {

  saup_bc_list <- parallel::mclapply(rds_yrs, mc.cores = 12,
    FUN = function(x) {
      # x <- rds_yrs[length(rds_yrs)]
      tmp_df <- readRDS(file.path(dir_data, x))
      tmp_df <- tmp_df %>%
        select(year, cell_id, catch_sum,
               sector_type_id, fishing_entity_id, 
               taxon_key, taxon_scientific_name, taxon_common_name,
               functional_group_id,
               commercial_group_id,
               catch_status, reporting_status,
               catch_sum) %>%
        filter(cell_id %in% ohibc_cells)
    })
  
  saup_bc_df <- saup_bc_list %>%
    setNames(rds_yrs) %>%
    bind_rows(.id = 'rds_file')
  
  saup_taxon_keys <- saup_bc_df %>%
    select(taxon_key, taxon_scientific_name, taxon_common_name) %>%
    distinct() %>%
    arrange(taxon_key)
  
  write_csv(saup_taxon_keys, file.path(dir_goal, 'saup', '2_taxon_keys_allbc.csv'))
  
  saup_bc_df <- saup_bc_df %>%
    select(-taxon_common_name, -taxon_scientific_name, -rds_file)
  write_csv(saup_bc_df, saup_raw_file)
  
} else {
  message('BC-specific SAUP data already present: ', saup_raw_file)
  
  git_prov(saup_raw_file, filetype = 'output')
  
}

```

This chunk also creates a taxon key lookup, at `~/github/ohibc/prep/fis/v2017/saup/2_taxon_keys_allbc.csv`.  This key lookup will form the basis for an OHIBC specific taxon list, associating SAUP taxa with RAM taxa.

### Associate SAUP stocks with RAM stocks

Clean up this raw list: manually tweak herring name (_Clupea pallasii pallasii_ to just _Clupea pallasii_) to match.  Where possible, match RAM stock scinames to SAUP stock scinames.

``` {r refine_taxon_keys}

saup_taxa <- read_csv(file.path(dir_goal, 'saup', '2_taxon_keys_allbc.csv')) %>%
  mutate(taxon_scientific_name = ifelse(taxon_scientific_name == 'Clupea pallasii pallasii', 
                                        'Clupea pallasii', 
                                        taxon_scientific_name))
ram_taxa <- read_csv(file.path(dir_goal, 'ram/1_bc_stocks_ohibc_ram.csv')) %>%
  select(stockid, stocklong, scientificname) %>%
  mutate(genus = str_extract(scientificname, '.*(?= )'))

saup_to_ram_spp <- saup_taxa %>%
  inner_join(ram_taxa, by = c('taxon_scientific_name' = 'scientificname'))
saup_to_ram_gen <- saup_taxa %>%
  inner_join(ram_taxa, by = c('taxon_scientific_name' = 'genus'))
saup_to_ram <- bind_rows(saup_to_ram_spp, saup_to_ram_gen) %>%
  mutate(scientificname = ifelse(is.na(scientificname), taxon_scientific_name, scientificname)) %>%
  distinct()
saup_to_ram_non <- saup_taxa %>%
  filter(!taxon_key %in% saup_to_ram$taxon_key) %>%
  bind_rows(ram_taxa %>%
              filter(!stockid %in% saup_to_ram$stockid)) %>%
  mutate(match = 'none')

saup_to_ram <- saup_to_ram %>%
  bind_rows(saup_to_ram_non) %>%
  select(-genus)
  
  
write_csv(saup_to_ram, file.path(dir_goal, 'saup/2_saup_to_ram_raw.csv'))


DT::datatable(saup_to_ram)
```

This raw file is based on matches of scientific name or genus.  

See `2a_plot_saup.Rmd` to visually check whether or not each taxa is reported within the OHIBC EEZ (note some reported in US or high seas may show up at the edges of the map, but do not reflect actual distribution in BC).  

Checking species matches against valid taxa reporting, some problems show up:

* Pacific Sardines (_Sardinops sagax_) do not have valid reported values in BC, despite species match (to cells in US).  Assign to family _Clupeidae_ level (400043).
* Flatfishes do not have valid reported cells at species or genus level in BC.  Assign to family _Pleuronectidae_ (400440):
    * RSOLE5AB and HSTR: Rock sole
    * ESOLEHS: English sole
* Most Rockfish are reported at species level in US but not BC.  Pacific Perch is a _Sebastes_ but maps look valid (600504, _Sebastes alutus_).  Unfortunately, SAUP reporting at the _Sebastes_ level (501135) also looks questionable.  These will be assigned to _Sebastidae_ level (400573):
    * BOCACCBCW: Bocaccio
    * CROCKWCVANISOGQCI: Canary rockfish
    * YEYEROCKPCOASTIN: Yelloweye rockfish
    * QROCKPCOASTOUT and IN: Quillback rockfish
* Northern Shrimp (_Pandalus borealis_) and Sidestripe Shrimp (_Pandalopsis dispar_) are not seemingly reported in BC at species, genus (_Pandalus_), or family level (_Pandalidae_).  These will be assigned to order (_Decapoda_) level (390013).
* Tunas and billfishes:
    * Pacific Bluefin Tuna (_Thunnus orientalis_) matches at species level, but not reported in BC at that level.
    * Other RAM tuna stocks do not seem to be reported at species or genus level in BC, and species level reporting in open ocean seems to taper out before it reaches far north.  This should be verified with DFO folks to decide how to handle these.  These have time series data in RAM.  Include at family level (_Scombridae_ - mackerels, tunas, bonitos)?
        * ALBANPAC: Albacore (though there is a fishery for these!)
        * BIGEYECWPAC and EPAC: Bigeye tuna
        * YFINCWPAC and EPAC: Yellowfin tuna
    * RAM billfish stocks: no match at species, genus, family; would fall into order _Perciformes_ I think, but no valid data there either.  These species have time series data in RAM.  Unless DFO folks really want to include these, exclude from the analysis.
        * BMARLINPAC: Blue marlin
        * SWORDEPAC and NPAC: Swordfish

In some cases, DFO data may be available with spatialized catch (e.g. shrimps) that could be used instead of SAUP.

``` {r clean_saup}

saup_to_ram <- read_csv(file.path(dir_goal, 'saup', '2_saup_to_ram_raw.csv'))
saup_taxa   <- read_csv(file.path(dir_goal, 'saup', '2_taxon_keys_allbc.csv')) %>%
  select(taxon_key, taxon_scientific_name)

saup_ram_fix <- c('Clupeidae'      = 'SARD',
                  'Pleuronectidae' = 'RSOLE', 
                  'Pleuronectidae' = 'ESOLE',
                  'Sebastidae'     = 'BOCACC',   
                  'Sebastidae'     = 'CROCK',
                  'Sebastidae'     = 'YEYEROCK',
                  'Sebastidae'     = 'QROCK',
                  'Decapoda'       = 'PANDAL',   
                  'Decapoda'       = 'SSHRIMP',
                  'Scombridae'     = 'YFIN',
                  'Scombridae'     = 'BIGEYE',  
                  'Scombridae'     = 'ALBA',
                  'Scombridae'     = 'PACBTUNA')

fix_ids <- saup_to_ram %>%
  filter(str_detect(stockid, paste(saup_ram_fix, collapse = '|'))) %>% 
  rowwise() %>%
  mutate(taxon_scientific_name = names(saup_ram_fix)[str_detect(stockid, saup_ram_fix)]) %>%
  ungroup() %>%
  select(stockid, taxon_scientific_name) %>%
  left_join(saup_taxa, by = 'taxon_scientific_name')

saup_to_ram_clean <- saup_to_ram %>%
  filter(!stockid %in% fix_ids$stockid) %>%
  select(stockid, taxon_scientific_name, taxon_key) %>%
  bind_rows(fix_ids) %>%
  filter(!is.na(stockid) & !is.na(taxon_key))

saup_to_ram_clean <- saup_to_ram_clean %>%
  mutate('key_level' = floor(taxon_key/1e5),
         match_level = ifelse(key_level == 3, 'order',   NA),
         match_level = ifelse(key_level == 4, 'family',  match_level),
         match_level = ifelse(key_level == 5, 'genus',   match_level),
         match_level = ifelse(key_level == 6, 'species', match_level)) %>%
  select(-key_level) %>%
  distinct()

write_csv(saup_to_ram_clean, file.path(dir_goal, 'saup', '2_saup_to_ram_clean.csv'))

```

## Trim SAUP data to just those used in OHIBC analysis

Identify the SAUP stocks in the BC area that have RAM data, and write to a github-available file.

``` {r trim_saup_data}

saup_to_ram_clean <- read_csv(file.path(dir_goal, 'saup', '2_saup_to_ram_clean.csv'))

saup_raw <- read_csv(file.path(dir_goal_anx, 'saup/2_saup_bc_raw.csv'))

saup_clean <- saup_raw %>%
  filter(taxon_key %in% saup_to_ram_clean$taxon_key)

write_csv(saup_clean, file.path(dir_goal, 'saup', '2_saup_bc_catch_by_cell.csv'))

```

-----

``` {r provenance, results = 'asis'}
prov_wrapup(commit_outputs = FALSE)
```
